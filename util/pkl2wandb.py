# MIT License

# Copyright (c) 2025 ReinFlow Authors

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.


# Finish the run
import os
import pickle
import wandb
import torch

def upload_pkl_to_wandb(
    pkl_path,
    project_name="my_project",
    entity=None,              # e.g. "my_team" if needed
    run_name=None,
    resume=False,
):
    """
    Loads .pkl file generated by training logs and pushes its entries to WandB.
    """

    assert os.path.exists(pkl_path), f"File not found: {pkl_path}"

    # Load data
    with open(pkl_path, "rb") as f:
        run_results = pickle.load(f)

    if not isinstance(run_results, list):
        raise ValueError("Expected list of dicts in pkl file (run_results format).")

    print(f"Loaded {len(run_results)} log entries from {pkl_path}")

    # Initialize WandB
    wandb.init(
        project=project_name,
        entity=entity,
        name=run_name or os.path.basename(pkl_path).replace(".pkl", ""),
        resume="allow" if resume else None,
    )

    # Push logs entry-by-entry
    for entry in run_results:
        itr = entry.get("itr", None)
        data = {}

        for key, value in entry.items():
            # Skip unnecessary nested stuff
            if key.startswith("self."):
                continue
            if isinstance(value, torch.Tensor):
                data[key] = value.item()
            elif isinstance(value, (int, float)):
                data[key] = value
            # ignore dicts/lists that aren't metrics
            elif isinstance(value, dict):
                # flatten if simple dict
                for sub_k, sub_v in value.items():
                    if isinstance(sub_v, (int, float)):
                        data[f"{key}/{sub_k}"] = sub_v
            # skip trajectory arrays etc.
            else:
                continue

        if data:
            wandb.log(data, step=itr, commit=True)

    print("âœ… Successfully uploaded all entries to WandB.")
    wandb.finish()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Upload run_results .pkl logs to WandB")
    parser.add_argument("--pkl", type=str, required=True, help="Path to .pkl file")
    parser.add_argument("--project", type=str, default="my_project", help="WandB project name")
    parser.add_argument("--entity", type=str, default=None, help="WandB entity (team/user)")
    parser.add_argument("--name", type=str, default=None, help="Run name on WandB")
    parser.add_argument("--resume", action="store_true", help="Resume existing WandB run")
    args = parser.parse_args()

    upload_pkl_to_wandb(
        pkl_path=args.pkl,
        project_name=args.project,
        entity=args.entity,
        run_name=args.name,
        resume=args.resume,
    )
